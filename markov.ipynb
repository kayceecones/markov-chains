{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams and Markov Chains for a Girl\n",
    "\n",
    "First, read our input text from a file and clean it into a list of words without special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start',\n",
      " 'of',\n",
      " 'the',\n",
      " 'project',\n",
      " 'gutenberg',\n",
      " 'ebook',\n",
      " \"alice's\",\n",
      " 'adventures',\n",
      " 'in',\n",
      " 'wonderland']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "def clean(input_text):\n",
    "    result = input_text\n",
    "\n",
    "    special_chars = [\".\", \"\\n\", \";\", \"?\", \"!\", \":\", \",\", \"(\", \")\", \"[\", \"]\", \"\\\"\", \"“\", \"”\", \"*\"]\n",
    "\n",
    "    for char in special_chars:\n",
    "        result = result.replace(char, \" \" if char == \"\\n\" else \"\")\n",
    "\n",
    "    return result.lower()\n",
    "\n",
    "\n",
    "# Clean up the input text\n",
    "def split_and_dropnulls(input_text):\n",
    "    words = input_text.split(\" \")\n",
    "\n",
    "    non_empty_words = [word for word in words if word != '']\n",
    "    return non_empty_words\n",
    "\n",
    "with open('alice.txt', 'r') as alice_file: \n",
    "    alice_text = ' '.join(alice_file.readlines())\n",
    "\n",
    "alice_words = split_and_dropnulls(clean(alice_text))\n",
    "pprint(alice_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split the text into pairs of two (later, N) words at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('start', 'of'),\n",
      " ('of', 'the'),\n",
      " ('the', 'project'),\n",
      " ('project', 'gutenberg'),\n",
      " ('gutenberg', 'ebook'),\n",
      " ('ebook', \"alice's\"),\n",
      " (\"alice's\", 'adventures'),\n",
      " ('adventures', 'in'),\n",
      " ('in', 'wonderland'),\n",
      " ('wonderland', 'cover')]\n"
     ]
    }
   ],
   "source": [
    "alice_pairs = [(alice_words[i], alice_words[i+1]) for i in range(len(alice_words)-1)]\n",
    "pprint(alice_pairs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the frequency of each pair within the set of pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('said', 'the'), 209),\n",
      " (('of', 'the'), 132),\n",
      " (('said', 'alice'), 115),\n",
      " (('in', 'a'), 98),\n",
      " (('and', 'the'), 80),\n",
      " (('in', 'the'), 79),\n",
      " (('it', 'was'), 73),\n",
      " (('to', 'the'), 69),\n",
      " (('the', 'queen'), 65),\n",
      " (('as', 'she'), 61)]\n"
     ]
    }
   ],
   "source": [
    "pair_counts = Counter(alice_pairs)\n",
    "\n",
    "frequencies = pair_counts.most_common(10)\n",
    "pprint(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! The final model has size: 1310808 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "\n",
    "def markov_model(sequence: list, n: int = 2):\n",
    "    \"\"\"\n",
    "    Create a Markov model (represented as a dict) from the given input sequence, \n",
    "    using N-grams of size {n}\n",
    "    \"\"\"\n",
    "    model = {}\n",
    "    sequence = list(sequence[:]) + [None]\n",
    "    for starting_position in range(len(sequence) - n):\n",
    "        current_ngram = tuple(sequence[starting_position:starting_position + n])\n",
    "        next_item = sequence[starting_position + n]\n",
    "        \n",
    "        if current_ngram not in model: \n",
    "            model[current_ngram] = [next_item]\n",
    "        else:\n",
    "            model[current_ngram].append(next_item)\n",
    "\n",
    "    return model\n",
    "\n",
    "alice_model = markov_model(alice_text, 5)\n",
    "print(f'Finished training! The final model has size: {sys.getsizeof(alice_model)} bytes')\n",
    "# pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Markov model of our text, we can use it to generate more text that \"looks like\" the source material:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red,” she tree inches deepest concert!” and I declare,\n",
      "            *\n",
      " “Come, the shook the arches of being of find of more could all this way of smoking and the Queen’s argument she hear you!” But he went on, Alice.\n",
      " \n",
      " “It isn’t one; “at least notion is, that Dormouse, which seem to be sending its feet high. “Why, then a really you invented at it make out a piteous tone to looked at it might Footman seemed to herself, and the meet Will these stretched by the conversation the King about me, pleased some otherwise, turned in her handed another.”\n",
      " \n",
      " Alice waited pale animals with passage: and she hearing at all, beautiful, be hungry to about for all,” Alice.\n",
      " \n",
      " “No,” said Alice replied ever saw the Cat. “I’ve got up in silent, while the puppy was, and the Mouse’s the Queen.\n",
      " \n",
      " The Hatter now,” thought it spoke for sneeze, were.\n",
      " \n",
      " Alice all the Duchess, digging for some to a great made her friends to learn it.” Alice.\n",
      " \n",
      " Alice, and look and shower of laughed deep voice said Alice turns out it’s laid his more puzzle!” said the Hatter a white;\n",
      " And she three inches left foot, Esq.,\n",
      "     Alice, “but I know better. He came thing upset to herself.”\n",
      " \n",
      " “Well, I never! And the March Hare meekly: “but you know which way from a Caterpillar and her. The Cat.\n",
      " Who Stole this way! Stop think!” (Dinah my ways hate cattle golden key, thought, so that to the high, “I wondering what curious tone, and said the name suddenly so,” said the Lizard in and beating for a minute, nursing yourse you see, and see herself from his shoes and asking, and the Gryphon, and when the Conqueror, with tears. “If I or she stop the verse,” said Alice staring made out of whiting, and said the Gryphon said, just be impossible.\n",
      " \n",
      " “That’s no noticing round the Gryphon went back to they’d take the moment!”\n",
      " \n",
      " The Mouse folded hoarse ground—and them, all him as he strange, by thing!”\n",
      " \n",
      " “You ought, “it mean while shall I know, my dears! It’ll make out what am I to go down, and passage if I’m too much stuff,” the wi"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate(n, model, start=None, max_length=100):\n",
    "    if start is None:\n",
    "        start = random.choice(list(model.keys()))\n",
    "    \n",
    "    output = list(start)\n",
    "\n",
    "    for i in range(max_length):\n",
    "        start = tuple(output[-n:])\n",
    "        next_item = random.choice(model[start])\n",
    "\n",
    "        if next_item is None:\n",
    "            break\n",
    "        else:\n",
    "            output.append(next_item)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "alice_result = generate(5, alice_model, max_length=2000)\n",
    "for char in alice_result:\n",
    "    print(char, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! The final model has size: 5242968 bytes\n"
     ]
    }
   ],
   "source": [
    "with open('bible.txt', 'r') as bible_file: \n",
    "    bible_text = ' '.join(bible_file.readlines())\n",
    "\n",
    "# Train a model on it \n",
    "bible_model = markov_model(bible_text, n=5)\n",
    "\n",
    "print(f'Finished training! The final model has size: {sys.getsizeof(bible_model)} bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " reigned to be\n",
      " deny him, had him.\n",
      " \n",
      " 20:13 But I pass for her, and whole earth be in goings: the\n",
      " top of his handmaid, What prevailed with\n",
      " thence after thou enemy,\n",
      " former\n",
      " the wrought to do enquire any more thee.\n",
      " \n",
      " 119:39 And he whom the Gentiles and the son of the\n",
      " greatly image, and is restings of this destruct me: 32:22 This stead of all my vessels\n",
      " of the world, even away from a month at Jacob.\n",
      " \n",
      " 13:15 And all\n",
      " then her end of Gibeah, and carry thee,\n",
      " again: there shall set the sons of silver, and destroy the power, nor the mount Ephraim, were was Elisha said unto them, that him.\n",
      " \n",
      " 27:15 Thomas, one angels of the presentence say unto us, if the house of the\n",
      " Father’s sake Martha was against he may become out with a bush burned in his time? why wife, and roll: and thee: for ever.\n",
      " \n",
      " 36:4 And he spoken with him, the Lord: the Amorites and\n",
      " Beelzebub cast heard\n",
      " shall be affliction saw the weapon, he led that the\n",
      " dead: the Reuel, and all Israel shall stand unsearching, nor pollute "
     ]
    }
   ],
   "source": [
    "# Generate some more \"bible\" with it\n",
    "bible_result = generate(n=5, model=bible_model, max_length=1000)\n",
    "\n",
    "for char in bible_result:\n",
    "    print(char, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do it to the Grateful Dead. (Do you know the grateful dead?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! The final model has size: 589920 bytes\n"
     ]
    }
   ],
   "source": [
    "with open('gdead.txt', 'r') as dead_file: \n",
    "    dead_text = ' '.join(dead_file.readlines())\n",
    "\n",
    "# Train a model on it \n",
    "dead_model = markov_model(dead_text, n=5)\n",
    "\n",
    "print(f'Finished training! The final model has size: {sys.getsizeof(dead_model)} bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d red grenadine,\n",
      " It's nothin's gettin' on the wall away I didn't have to fly,\n",
      " You know, I just out slow\n",
      " And this grade.\n",
      " Call for I feel a deep or wide, if I had too steel, made to shine, their head a harder to fly,\n",
      " You get me up the fly,\n",
      " I went his whole round, and keep watching to be the song for very lonely swallows for very long since I've chunder in to chunder with me?\n",
      " \n",
      " Maybe the same story Rider\n",
      " \n",
      " So instead I've chuckled like the West Mountain,\n",
      " And a goddess of the rainstorm, I ducked myself to move,\n",
      " The bastard barely swallows for I feeling a maching I got no heart. You love him don't tell.\n",
      " Cost two with a Mexican\n",
      " The brakes dynamite to go,\n",
      " I turned around, and like the desert sands.\n",
      " \n",
      " Just out don't be a collector of the axis.\n",
      " So if you had to bite,\n",
      " That's why if you\n",
      " \n",
      " Well, you go.\n",
      " Ain't got a loving to Kansas City, Kansas City where anything To Try\n",
      " \n",
      " Well, well your part.\n",
      " \n",
      " Just as a pistol but try dragging my friend; better but nothing to the hill the southwe"
     ]
    }
   ],
   "source": [
    "# Generate some more \"dead songs\" with it\n",
    "dead_result = generate(n=5, model=dead_model, max_length=1000)\n",
    "\n",
    "for char in dead_result:\n",
    "    print(char, end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
