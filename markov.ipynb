{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams and Markov Chains for a Girl\n",
    "\n",
    "First, read our input text from a file and clean it into a list of words without special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down',\n",
      " 'the',\n",
      " 'rabbit-hole',\n",
      " 'alice',\n",
      " 'was',\n",
      " 'beginning',\n",
      " 'to',\n",
      " 'get',\n",
      " 'very',\n",
      " 'tired']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "def clean(input_text):\n",
    "    result = input_text\n",
    "\n",
    "    special_chars = [\".\", \"\\n\", \";\", \"?\", \"!\", \":\", \",\", \"(\", \")\", \"[\", \"]\", \"\\\"\", \"“\", \"”\", \"*\"]\n",
    "\n",
    "    for char in special_chars:\n",
    "        result = result.replace(char, \" \" if char == \"\\n\" else \"\")\n",
    "\n",
    "    return result.lower()\n",
    "\n",
    "\n",
    "# Clean up the input text\n",
    "def split_and_dropnulls(input_text):\n",
    "    words = input_text.split(\" \")\n",
    "\n",
    "    non_empty_words = [word for word in words if word != '']\n",
    "    return non_empty_words\n",
    "\n",
    "with open('alice.txt', 'r') as alice_file: \n",
    "    alice_text = ' '.join(alice_file.readlines())\n",
    "\n",
    "alice_words = split_and_dropnulls(clean(alice_text))\n",
    "pprint(alice_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split the text into pairs of two (later, N) words at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('down', 'the'),\n",
      " ('the', 'rabbit-hole'),\n",
      " ('rabbit-hole', 'alice'),\n",
      " ('alice', 'was'),\n",
      " ('was', 'beginning'),\n",
      " ('beginning', 'to'),\n",
      " ('to', 'get'),\n",
      " ('get', 'very'),\n",
      " ('very', 'tired'),\n",
      " ('tired', 'of')]\n"
     ]
    }
   ],
   "source": [
    "alice_pairs = [(alice_words[i], alice_words[i+1]) for i in range(len(alice_words)-1)]\n",
    "pprint(alice_pairs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the frequency of each pair within the set of pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('said', 'the'), 209),\n",
      " (('of', 'the'), 131),\n",
      " (('said', 'alice'), 115),\n",
      " (('in', 'a'), 97),\n",
      " (('and', 'the'), 80),\n",
      " (('in', 'the'), 79),\n",
      " (('it', 'was'), 73),\n",
      " (('to', 'the'), 69),\n",
      " (('the', 'queen'), 65),\n",
      " (('as', 'she'), 61)]\n"
     ]
    }
   ],
   "source": [
    "pair_counts = Counter(alice_pairs)\n",
    "\n",
    "frequencies = pair_counts.most_common(10)\n",
    "pprint(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! The final model has size: 1310808 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "\n",
    "def markov_model(sequence: list, n: int = 2):\n",
    "    \"\"\"\n",
    "    Create a Markov model (represented as a dict) from the given input sequence, \n",
    "    using N-grams of size {n}\n",
    "    \"\"\"\n",
    "    model = {}\n",
    "    sequence = list(sequence[:]) + [None]\n",
    "    for starting_position in range(len(sequence) - n):\n",
    "        current_ngram = tuple(sequence[starting_position:starting_position + n])\n",
    "        next_item = sequence[starting_position + n]\n",
    "        \n",
    "        if current_ngram not in model: \n",
    "            model[current_ngram] = [next_item]\n",
    "        else:\n",
    "            model[current_ngram].append(next_item)\n",
    "\n",
    "    return model\n",
    "\n",
    "alice_model = markov_model(alice_text, 5)\n",
    "print(f'Finished training! The final model has size: {sys.getsizeof(alice_model)} bytes')\n",
    "# pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Markov model of our text, we can use it to generate more text that \"looks like\" the source material:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I—”\n",
      " \n",
      " “I’m afraid of useful, beautiful Soup!”\n",
      " \n",
      " “Come back to the\n",
      "     *     cur, ‘Such\n",
      "         old Magpie began move one of voice hearthrug,\n",
      "      *      Improve I can’t under when it was a porpoise indignantly. As she began to this father you getting while think,” said Alice: “tell you know,” he said the Gryphon, but now hastily. “Considered “She’s so much matter instant to herself no tears running overcome very tired a sleep it too: but nonsense length, which is while this?” She at last the chimney, and hands, won’t, that became running down upon Alice thought to be like to it written to try is, then all manner, they had never said very day—”\n",
      " \n",
      " “What she said to herself suddenly: Alice beheaded Alice ventures for she came up: if nothing their simple rule: you’re the name: however, with a little sighed deep again, and said the fan, and as serpent?”\n",
      " \n",
      " “And yet—Oh! the other moment.\n",
      " \n",
      " “Will you, will these were,” said Alice, seriously, thought to herself, as she way of taking down over all, and Alice, (“the whiting if a few minute.\n",
      " \n",
      " “It’s try the she hastily, she tops of foot as a dreadful this continued things at the Duchess! Oh dear, and the earth! How the Mock Turtle.\n",
      " \n",
      " “Well, it’s getting of the White Rabbit now and why the March Hare.\n",
      " \n",
      " “Then, you like a well she felt a very to everything in Coils.”\n",
      " \n",
      " “There was just there’s no “One, the Dormouse.\n",
      " \n",
      " “But the world you’re a Duchess she thought thing; and did not muchness”—did you, will talk about her their face is of the procession.”\n",
      " \n",
      " The Fish-Footman. “How could say if I must miss my his time, but at all,” said “No, no! There there was very near enough hatch"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ing off your Majesty!” thought to beginning his eyes.—“Tell upon the shook its wings. “I don’t ever without again!” said the Duchess to be the Hatter; “don’t know what you: you pleaders, and was to have did, sir—” They all day about thought to shower of think about from a boon,\n",
      " Was kind of this, she was all my life.\n",
      " \n",
      " “Well, I never lefthand began"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate(n, model, start=None, max_length=100):\n",
    "    if start is None:\n",
    "        start = random.choice(list(model.keys()))\n",
    "    \n",
    "    output = list(start)\n",
    "\n",
    "    for i in range(max_length):\n",
    "        start = tuple(output[-n:])\n",
    "        next_item = random.choice(model[start])\n",
    "\n",
    "        if next_item is None:\n",
    "            break\n",
    "        else:\n",
    "            output.append(next_item)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "alice_result = generate(5, alice_model, max_length=2000)\n",
    "for char in alice_result:\n",
    "    print(char, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! The final model has size: 5242968 bytes\n"
     ]
    }
   ],
   "source": [
    "with open('bible.txt', 'r') as bible_file: \n",
    "    bible_text = ' '.join(bible_file.readlines())\n",
    "\n",
    "# Train a model on it \n",
    "bible_model = markov_model(bible_text, n=5)\n",
    "\n",
    "print(f'Finished training! The final model has size: {sys.getsizeof(bible_model)} bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " reigned to be\n",
      " deny him, had him.\n",
      " \n",
      " 20:13 But I pass for her, and whole earth be in goings: the\n",
      " top of his handmaid, What prevailed with\n",
      " thence after thou enemy,\n",
      " former\n",
      " the wrought to do enquire any more thee.\n",
      " \n",
      " 119:39 And he whom the Gentiles and the son of the\n",
      " greatly image, and is restings of this destruct me: 32:22 This stead of all my vessels\n",
      " of the world, even away from a month at Jacob.\n",
      " \n",
      " 13:15 And all\n",
      " then her end of Gibeah, and carry thee,\n",
      " again: there shall set the sons of silver, and destroy the power, nor the mount Ephraim, were was Elisha said unto them, that him.\n",
      " \n",
      " 27:15 Thomas, one angels of the presentence say unto us, if the house of the\n",
      " Father’s sake Martha was against he may become out with a bush burned in his time? why wife, and roll: and thee: for ever.\n",
      " \n",
      " 36:4 And he spoken with him, the Lord: the Amorites and\n",
      " Beelzebub cast heard\n",
      " shall be affliction saw the weapon, he led that the\n",
      " dead: the Reuel, and all Israel shall stand unsearching, nor pollute "
     ]
    }
   ],
   "source": [
    "# Generate some more \"bible\" with it\n",
    "bible_result = generate(n=5, model=bible_model, max_length=1000)\n",
    "\n",
    "for char in bible_result:\n",
    "    print(char, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do it to the Grateful Dead. (Do you know the grateful dead?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training! The final model has size: 589920 bytes\n"
     ]
    }
   ],
   "source": [
    "with open('gdead.txt', 'r') as dead_file: \n",
    "    dead_text = ' '.join(dead_file.readlines())\n",
    "\n",
    "# Train a model on it \n",
    "dead_model = markov_model(dead_text, n=5)\n",
    "\n",
    "print(f'Finished training! The final model has size: {sys.getsizeof(dead_model)} bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d red grenadine,\n",
      " It's nothin's gettin' on the wall away I didn't have to fly,\n",
      " You know, I just out slow\n",
      " And this grade.\n",
      " Call for I feel a deep or wide, if I had too steel, made to shine, their head a harder to fly,\n",
      " You get me up the fly,\n",
      " I went his whole round, and keep watching to be the song for very lonely swallows for very long since I've chunder in to chunder with me?\n",
      " \n",
      " Maybe the same story Rider\n",
      " \n",
      " So instead I've chuckled like the West Mountain,\n",
      " And a goddess of the rainstorm, I ducked myself to move,\n",
      " The bastard barely swallows for I feeling a maching I got no heart. You love him don't tell.\n",
      " Cost two with a Mexican\n",
      " The brakes dynamite to go,\n",
      " I turned around, and like the desert sands.\n",
      " \n",
      " Just out don't be a collector of the axis.\n",
      " So if you had to bite,\n",
      " That's why if you\n",
      " \n",
      " Well, you go.\n",
      " Ain't got a loving to Kansas City, Kansas City where anything To Try\n",
      " \n",
      " Well, well your part.\n",
      " \n",
      " Just as a pistol but try dragging my friend; better but nothing to the hill the southwe"
     ]
    }
   ],
   "source": [
    "# Generate some more \"dead songs\" with it\n",
    "dead_result = generate(n=5, model=dead_model, max_length=1000)\n",
    "\n",
    "for char in dead_result:\n",
    "    print(char, end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
